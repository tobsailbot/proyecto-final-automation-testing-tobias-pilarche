
# ğŸ§ª Proyecto Final - Framework de AutomatizaciÃ³n de Pruebas - Tobias Pilarche

Este repositorio contiene el Trabajo Final Integrador del curso de Testing QA. Se trata de un framework de automatizaciÃ³n robusto y escalable desarrollado en Python, diseÃ±ado para validar tanto interfaces de usuario (UI) como interfaces de programaciÃ³n de aplicaciones (API).

## ğŸ¯ PropÃ³sito del Proyecto

El objetivo principal es demostrar la aplicaciÃ³n de conocimientos avanzados de automatizaciÃ³n mediante la creaciÃ³n de un framework que incluye:

1.  **Pruebas de UI (End-to-End):** AutomatizaciÃ³n de flujos crÃ­ticos de compra en el sitio *SauceDemo* (Login, Inventario, Carrito) utilizando **Selenium WebDriver**.
2.  **Pruebas de API:** ValidaciÃ³n de cÃ³digos de estado y estructura de datos en endpoints REST de *JSONPlaceholder* utilizando **Requests**.
3.  **Patrones de DiseÃ±o:** ImplementaciÃ³n del patrÃ³n **Page Object Model (POM)** para garantizar un cÃ³digo mantenible, modular y fÃ¡cil de leer.
4.  **Reportes:** GeneraciÃ³n automÃ¡tica de evidencia visual (reportes HTML y capturas de pantalla) para facilitar el anÃ¡lisis de resultados.

## ğŸ›  TecnologÃ­as Utilizadas

*   **Lenguaje:** [Python 3.x](https://www.python.org/)
*   **Orquestador de Pruebas:** [Pytest](https://docs.pytest.org/) (Manejo de fixtures, aserciones y ejecuciÃ³n).
*   **AutomatizaciÃ³n Web:** [Selenium WebDriver](https://www.selenium.dev/).
*   **GestiÃ³n de Drivers:** [Webdriver Manager](https://pypi.org/project/webdriver-manager/) (Descarga automÃ¡tica de ChromeDriver/GeckoDriver).
*   **AutomatizaciÃ³n de API:** [Requests](https://pypi.org/project/requests/).
*   **Reportes:** [Pytest-HTML](https://pypi.org/project/pytest-html/).

## ğŸ“‚ Estructura del Proyecto

La organizaciÃ³n de carpetas sigue las mejores prÃ¡cticas de la industria:

```text
proyecto_final/
â”œâ”€â”€ pages/                  # Page Object Model (LÃ³gica de las pÃ¡ginas web)
â”‚   â”œâ”€â”€ base_page.py        # MÃ©todos genÃ©ricos (Wrapper de Selenium)
â”‚   â”œâ”€â”€ login_page.py       # Acciones de la pÃ¡gina de Login
â”‚   â””â”€â”€ inventory_page.py   # Acciones del inventario y carrito
â”œâ”€â”€ tests/                  # Scripts de prueba
â”‚   â”œâ”€â”€ ui/                 # Tests de Interfaz (Selenium)
â”‚   â””â”€â”€ api/                # Tests de Backend (Requests)
â”œâ”€â”€ data/                   # Datos de prueba externos (JSON/CSV)
â”œâ”€â”€ reports/                # AquÃ­ se generan los Reportes HTML y Screenshots
â”œâ”€â”€ venv/                   # Entorno virtual (no se sube al repo)
â”œâ”€â”€ conftest.py             # ConfiguraciÃ³n global (Hooks, Setup del Driver)
â”œâ”€â”€ pytest.ini              # ConfiguraciÃ³n de ejecuciÃ³n y logs
â”œâ”€â”€ requirements.txt        # Lista de dependencias del proyecto
â””â”€â”€ README.md               # DocumentaciÃ³n del proyecto
```

## âš™ï¸ Â¿CÃ³mo instalar las dependencias?

Seguir estos pasos para configurar el entorno en tu mÃ¡quina local (Linux/Mac/Windows).

**1. Clonar el repositorio:**
```bash
git clone <URL_DEL_REPOSITORIO>
cd proyecto-final-automation
```

**2. Crear el Entorno Virtual:**
*En Linux/Debian:*
```bash
python3 -m venv venv
source venv/bin/activate
```
*En Windows:*
```bash
python -m venv venv
venv\Scripts\activate
```

**3. Instalar librerÃ­as:**
Una vez activo el entorno (verÃ¡s `(venv)` en la terminal), ejecuta:
```bash
pip install -r requirements.txt
```
*(Nota: Esto instalarÃ¡ Selenium, Pytest, Requests y todas las herramientas necesarias).*

## ğŸš€ Â¿CÃ³mo ejecutar las pruebas?

Gracias a la configuraciÃ³n en `pytest.ini`, el comando es muy sencillo. AsegÃºrate de tener el entorno virtual activado.

**Ejecutar TODAS las pruebas (UI + API):**
```bash
python3 -m pytest
```

## ğŸ“Š Â¿CÃ³mo interpretar los reportes generados?

Al finalizar la ejecuciÃ³n, se generarÃ¡ automÃ¡ticamente un archivo en la carpeta `reports/`:

1.  Abre el archivo **`reports/reporte_final.html`** en tu navegador (Chrome/Firefox).
2.  **Verde (Passed):** El test pasÃ³ exitosamente. Haz clic en la fila para ver el **Log detallado** (pasos realizados).
3.  **Rojo (Failed):** El test fallÃ³. Al expandirlo encontrarÃ¡s:
    *   **Error Log:** La razÃ³n tÃ©cnica del fallo.
    *   **Screenshot:** Una captura de pantalla automÃ¡tica del momento exacto del error (fundamental para debugging).

---
**Autor:** Tobias Pilarche
**Fecha:** Noviembre 2025
```

---